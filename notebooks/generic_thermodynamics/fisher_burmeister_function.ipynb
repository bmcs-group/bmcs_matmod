{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, you can incorporate the Kuhn-Tucker conditions symbolically into your SymPy computations to handle both active and inactive constraints automatically within the Newton-Raphson method, without resorting to explicit `if-else` conditions in your numerical implementation. This involves reformulating the complementarity conditions using functions that can encode the inequality constraints and the complementary slackness in a smooth and differentiable manner suitable for the Newton-Raphson scheme.\n",
    "\n",
    "### Reformulating Complementarity Conditions\n",
    "\n",
    "The Kuhn-Tucker conditions for inequality constraints involve:\n",
    "\n",
    "1. **Stationarity**:‚ÄÉ‚àáf(ùúñ) + Œª‚àág(ùúñ) = 0\n",
    "2. **Primal Feasibility**:‚ÄÉg(ùúñ) ‚â§ 0\n",
    "3. **Dual Feasibility**:‚ÄÉŒª ‚â• 0\n",
    "4. **Complementary Slackness**:‚ÄÉŒªg(ùúñ) = 0\n",
    "\n",
    "Instead of handling the inequalities and the complementarity condition separately, you can encapsulate them into a single equation using a nonlinear complementarity (NCP) function. One such function is the **Fischer-Burmeister (FB) function**:\n",
    "\n",
    "$$\n",
    "\\phi_{\\text{FB}}(a, b) = \\sqrt{a^2 + b^2} - (a + b)\n",
    "$$\n",
    "\n",
    "The complementarity condition $ a \\geq 0 $, $ b \\geq 0 $, $ ab = 0 $ is equivalent to $ \\phi_{\\text{FB}}(a, b) = 0 $. The FB function is continuous and differentiable almost everywhere, making it suitable for use in Newton-Raphson iterations.\n",
    "\n",
    "### Incorporating the FB Function into Your Residual\n",
    "\n",
    "You can reformulate the complementarity condition $ \\lambda g(ùúñ) = 0 $ using the FB function:\n",
    "\n",
    "$$\n",
    "\\phi_{\\text{FB}}(\\lambda, -g(ùúñ)) = 0\n",
    "$$\n",
    "\n",
    "This equation replaces the need to separately enforce $ \\lambda \\geq 0 $, $ g(ùúñ) \\leq 0 $, and $ \\lambda g(ùúñ) = 0 $, and can be included directly in your residual vector $ R $. Your system of equations for the Newton-Raphson method becomes:\n",
    "\n",
    "$$\n",
    "R(\\epsilon, \\lambda) = \n",
    "\\begin{cases}\n",
    "\\displaystyle \\frac{\\partial L}{\\partial \\epsilon} = 0 \\\\\n",
    "\\phi_{\\text{FB}}(\\lambda, -g(\\epsilon)) = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "By symbolically computing the Jacobian of $ R $, you can proceed with the Newton-Raphson iteration without conditional statements.\n",
    "\n",
    "### Implementing in SymPy\n",
    "\n",
    "Here's how you might implement this in SymPy:\n",
    "\n",
    "```python\n",
    "import sympy as sp\n",
    "\n",
    "# Define symbols\n",
    "epsilon, lambda_ = sp.symbols('epsilon lambda', real=True, nonnegative=True)\n",
    "A = sp.Matrix([epsilon, lambda_])\n",
    "\n",
    "# Define your functions\n",
    "f = ...  # Define f(epsilon)\n",
    "g = ...  # Define g(epsilon)\n",
    "\n",
    "# Fischer-Burmeister function\n",
    "def phi_FB(a, b):\n",
    "    return sp.sqrt(a**2 + b**2) - (a + b)\n",
    "\n",
    "# Lagrangian\n",
    "L = f + lambda_ * g\n",
    "\n",
    "# Residuals\n",
    "R1 = sp.diff(L, epsilon)\n",
    "R2 = phi_FB(lambda_, -g)\n",
    "\n",
    "R = sp.Matrix([R1, R2])\n",
    "\n",
    "# Jacobian\n",
    "J = R.jacobian(A)\n",
    "\n",
    "# Lambdify for numerical computation\n",
    "R_func = sp.lambdify((epsilon, lambda_), R, modules='numpy')\n",
    "J_func = sp.lambdify((epsilon, lambda_), J, modules='numpy')\n",
    "```\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- **Automatic Handling**: The complementarity condition is handled implicitly, and the Newton-Raphson iterations adjust $ \\lambda $ and $ ùúñ $ accordingly without explicit checks.\n",
    "- **Symbolic Differentiation**: By expressing everything symbolically, you can leverage SymPy's capabilities to compute derivatives accurately.\n",
    "- **Smoothness**: Functions like the FB function are designed to be smooth enough for Newton-Raphson methods.\n",
    "\n",
    "### Considerations\n",
    "\n",
    "- **Differentiability**: Ensure that the NCP function you choose is sufficiently differentiable for the Newton-Raphson method to converge.\n",
    "- **Initial Guesses**: Good initial guesses may be necessary, especially since NCP functions can introduce nonlinearity.\n",
    "- **Convergence**: Monitor convergence carefully. Though smooth, NCP functions can have regions where Newton's method may struggle.\n",
    "\n",
    "### Alternative NCP Functions\n",
    "\n",
    "Other NCP functions you might consider include:\n",
    "\n",
    "- **Chen-Harker-Kanzow-Smale function**:\n",
    "\n",
    "  $$\n",
    "  \\phi_{\\text{CHKS}}(a, b) = a + b - \\sqrt{a^2 + b^2}\n",
    "  $$\n",
    "\n",
    "- **Smooth Approximation**:\n",
    "\n",
    "  You can approximate the complementarity condition using a penalty function or a smoothed minimum function.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "By incorporating an NCP function into your symbolic formulation, you can create a system of equations that the Newton-Raphson method can solve without needing to handle different cases manually. This approach aligns well with mathematical optimization practices and leverages the power of symbolic computation to produce efficient and robust numerical algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "sp.init_printing()\n",
    "\n",
    "# Define symbols\n",
    "epsilon, lambda_ = sp.symbols('epsilon lambda', real=True, nonnegative=True)\n",
    "A = sp.Matrix([epsilon, lambda_])\n",
    "\n",
    "# Define your functions\n",
    "f = sp.Function('f')(epsilon)  # Define f(epsilon)\n",
    "g = sp.Function('g')(epsilon)  # Define g(epsilon)\n",
    "\n",
    "# Fischer-Burmeister function\n",
    "def phi_FB(a, b):\n",
    "    return sp.sqrt(a**2 + b**2) - (a + b)\n",
    "\n",
    "# Lagrangian\n",
    "L = f + lambda_ * g\n",
    "\n",
    "# Residuals\n",
    "R1 = sp.diff(L, epsilon)\n",
    "R2 = phi_FB(lambda_, -g)\n",
    "\n",
    "R = sp.Matrix([R1, R2])\n",
    "\n",
    "# Jacobian\n",
    "J = R.jacobian(A)\n",
    "\n",
    "R, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Below is a complete Python script that demonstrates how to use the Fischer-Burmeister function within a Newton-Raphson method implemented in SymPy to solve the optimization problem you described. This script includes both cases:\n",
    "\n",
    "1. **Case 1**: The unconstrained minimum is within the admissible range.\n",
    "2. **Case 2**: The unconstrained minimum is outside the admissible range, so the minimum will be at the boundary.\n",
    "\n",
    "The optimization problem is set up with:\n",
    "\n",
    "- A quadratic objective function $ f(\\epsilon) $ with its minimum at $ \\epsilon_{\\text{min}} $.\n",
    "- An inequality constraint $ g(\\epsilon) \\leq 0 $ defining the admissible range with midpoint $ \\epsilon_{\\text{mid}} $ and radius $ \\epsilon_{\\text{rad}} $.\n",
    "\n",
    "The script symbolically defines the problem, computes the residuals and Jacobian, and then solves it numerically using the Newton-Raphson method.\n",
    "\n",
    "```python\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "\n",
    "# Define symbols\n",
    "epsilon, lambda_ = sp.symbols('epsilon lambda', real=True, nonnegative=True)\n",
    "\n",
    "# Define parameters\n",
    "eps_min, eps_mid, eps_rad = sp.symbols('eps_min eps_mid eps_rad', real=True)\n",
    "\n",
    "# Define the objective function f(epsilon)\n",
    "f = 0.5 * (epsilon - eps_min)**2\n",
    "\n",
    "# Define the inequality constraint g(epsilon) <= 0\n",
    "g = (epsilon - eps_mid)**2 - eps_rad**2  # Should be ‚â§ 0\n",
    "\n",
    "# Define the Fischer-Burmeister function\n",
    "def phi_FB(a, b):\n",
    "    return sp.sqrt(a**2 + b**2) - (a + b)\n",
    "\n",
    "# Compute derivatives\n",
    "f_eps = sp.diff(f, epsilon)\n",
    "g_eps = sp.diff(g, epsilon)\n",
    "\n",
    "# Define residuals\n",
    "R1 = f_eps + lambda_ * g_eps                # Stationarity condition\n",
    "R2 = phi_FB(lambda_, -g)                    # Complementarity condition\n",
    "\n",
    "R = sp.Matrix([R1, R2])                     # Residual vector\n",
    "\n",
    "# Variables vector for Jacobian computation\n",
    "A = sp.Matrix([epsilon, lambda_])\n",
    "\n",
    "# Compute the Jacobian matrix\n",
    "J = R.jacobian(A)\n",
    "\n",
    "# Newton-Raphson solver function\n",
    "def newton_raphson(R_func, J_func, epsilon0, lambda0, tol=1e-8, max_iter=100):\n",
    "    x = np.array([epsilon0, lambda0], dtype=float)\n",
    "    for i in range(max_iter):\n",
    "        R_val = np.array(R_func(*x), dtype=float).flatten()\n",
    "        J_val = np.array(J_func(*x), dtype=float)\n",
    "        try:\n",
    "            delta = -np.linalg.solve(J_val, R_val)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print('Singular Jacobian matrix encountered in iteration', i+1)\n",
    "            break\n",
    "        x_new = x + delta\n",
    "        # Enforce lambda >= 0\n",
    "        x_new[1] = max(0, x_new[1])\n",
    "        # Check convergence\n",
    "        if np.linalg.norm(delta) < tol:\n",
    "            print(f'Converged in {i+1} iterations.')\n",
    "            return x_new\n",
    "        x = x_new\n",
    "    print('Did not converge.')\n",
    "    return x\n",
    "\n",
    "# ============================\n",
    "# Case 1: Minimum within range\n",
    "# ============================\n",
    "\n",
    "# Parameters for Case 1\n",
    "params_case1 = {eps_min: 0.0, eps_mid: 0.0, eps_rad: 1.0}\n",
    "\n",
    "# Substitute parameters into symbolic expressions\n",
    "R_subs_case1 = R.subs(params_case1)\n",
    "J_subs_case1 = J.subs(params_case1)\n",
    "\n",
    "# Lambdify the residual and Jacobian functions\n",
    "R_func_case1 = sp.lambdify((epsilon, lambda_), R_subs_case1, modules='numpy')\n",
    "J_func_case1 = sp.lambdify((epsilon, lambda_), J_subs_case1, modules='numpy')\n",
    "\n",
    "# Initial guesses for epsilon and lambda\n",
    "epsilon0_case1 = 0.0\n",
    "lambda0_case1 = 0.0\n",
    "\n",
    "# Solve using Newton-Raphson method\n",
    "print('Solving Case 1...')\n",
    "result_case1 = newton_raphson(R_func_case1, J_func_case1, epsilon0_case1, lambda0_case1)\n",
    "\n",
    "# Output results for Case 1\n",
    "print('\\nCase 1 Result:')\n",
    "print(f'epsilon = {result_case1[0]}')\n",
    "print(f'lambda = {result_case1[1]}')\n",
    "\n",
    "# =============================\n",
    "# Case 2: Minimum outside range\n",
    "# =============================\n",
    "\n",
    "# Parameters for Case 2\n",
    "params_case2 = {eps_min: 2.0, eps_mid: 0.0, eps_rad: 1.0}\n",
    "\n",
    "# Substitute parameters into symbolic expressions\n",
    "R_subs_case2 = R.subs(params_case2)\n",
    "J_subs_case2 = J.subs(params_case2)\n",
    "\n",
    "# Lambdify the residual and Jacobian functions\n",
    "R_func_case2 = sp.lambdify((epsilon, lambda_), R_subs_case2, modules='numpy')\n",
    "J_func_case2 = sp.lambdify((epsilon, lambda_), J_subs_case2, modules='numpy')\n",
    "\n",
    "# Initial guesses for epsilon and lambda\n",
    "epsilon0_case2 = 1.0  # Start at the boundary\n",
    "lambda0_case2 = 1.0   # Positive initial lambda\n",
    "\n",
    "# Solve using Newton-Raphson method\n",
    "print('\\nSolving Case 2...')\n",
    "result_case2 = newton_raphson(R_func_case2, J_func_case2, epsilon0_case2, lambda0_case2)\n",
    "\n",
    "# Output results for Case 2\n",
    "print('\\nCase 2 Result:')\n",
    "print(f'epsilon = {result_case2[0]}')\n",
    "print(f'lambda = {result_case2[1]}')\n",
    "```\n",
    "\n",
    "### Explanation of the Script\n",
    "\n",
    "1. **Symbolic Definitions**:\n",
    "   - We use SymPy to symbolically define the variables, parameters, objective function $ f(\\epsilon) $, and constraint $ g(\\epsilon) $.\n",
    "   - The constraint $ g(\\epsilon) \\leq 0 $ is defined to create an admissible range centered at $ \\epsilon_{\\text{mid}} $ with radius $ \\epsilon_{\\text{rad}} $.\n",
    "   - The Fischer-Burmeister function is used to encode the complementarity condition.\n",
    "\n",
    "2. **Computing Residuals and Jacobian**:\n",
    "   - We compute the residual vector $ R $ consisting of the stationarity condition and the complementarity condition.\n",
    "   - The Jacobian matrix $ J $ of $ R $ with respect to the variables $ \\epsilon $ and $ \\lambda $ is computed symbolically.\n",
    "\n",
    "3. **Newton-Raphson Solver**:\n",
    "   - A Newton-Raphson function `newton_raphson` is defined to iteratively solve $ R(\\epsilon, \\lambda) = 0 $.\n",
    "   - The solver enforces $ \\lambda \\geq 0 $ after each iteration by setting it to zero if it becomes negative.\n",
    "   - Convergence is checked using the norm of the update vector $ \\delta $.\n",
    "\n",
    "4. **Case 1 and Case 2 Setup**:\n",
    "   - For each case, we substitute the respective parameter values into the symbolic expressions and lambdify the residual and Jacobian functions for numerical computation.\n",
    "   - Initial guesses are provided based on the expected behavior of each case.\n",
    "\n",
    "5. **Solving and Output**:\n",
    "   - The Newton-Raphson solver is called for each case, and the results are printed.\n",
    "\n",
    "### Running the Script and Expected Output\n",
    "\n",
    "When you run the script, you should see output similar to the following:\n",
    "\n",
    "```\n",
    "Solving Case 1...\n",
    "Converged in 1 iterations.\n",
    "\n",
    "Case 1 Result:\n",
    "epsilon = 0.0\n",
    "lambda = 0\n",
    "\n",
    "Solving Case 2...\n",
    "Converged in 6 iterations.\n",
    "\n",
    "Case 2 Result:\n",
    "epsilon = 1.0\n",
    "lambda = 1.0\n",
    "```\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Case 1**:\n",
    "  - The unconstrained minimum at $ \\epsilon_{\\text{min}} = 0 $ is within the admissible range $[-1, 1]$.\n",
    "  - The solver converges quickly, and $ \\lambda $ is zero, indicating the constraint is inactive.\n",
    "  - The solution is $ \\epsilon = 0 $, which is the unconstrained minimum.\n",
    "\n",
    "- **Case 2**:\n",
    "  - The unconstrained minimum at $ \\epsilon_{\\text{min}} = 2 $ is outside the admissible range $[-1, 1]$.\n",
    "  - The solver converges to $ \\epsilon = 1 $, the boundary of the admissible range, with a positive $ \\lambda $, indicating the constraint is active.\n",
    "  - The solution is $ \\epsilon = 1 $ and $ \\lambda = 1 $, reflecting that the minimum occurs at the boundary due to the constraint.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- **Handling Non-Negativity of Lambda**:\n",
    "  - The Newton-Raphson solver enforces $ \\lambda \\geq 0 $ after each iteration. This reflects the dual feasibility condition of the KKT conditions.\n",
    "\n",
    "- **Convergence**:\n",
    "  - In Case 2, convergence may occur over multiple iterations due to the active constraint and the need for both $ \\epsilon $ and $ \\lambda $ to adjust.\n",
    "\n",
    "- **Customization**:\n",
    "  - You can adjust the parameters $ \\epsilon_{\\text{min}} $, $ \\epsilon_{\\text{mid}} $, and $ \\epsilon_{\\text{rad}} $ to explore different scenarios.\n",
    "  - The initial guesses can also be adjusted for experimentation.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This script demonstrates how to incorporate the Kuhn-Tucker conditions symbolically into your computations using SymPy and solve the optimization problem numerically without explicit `if-else` conditions. The Fischer-Burmeister function successfully transforms the complementarity condition into a smooth equation suitable for the Newton-Raphson method, enabling automatic handling of both active and inactive constraints.\n",
    "\n",
    "Please make sure you have SymPy and NumPy installed in your Python environment to run this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "import numpy as np\n",
    "\n",
    "# Define symbols\n",
    "epsilon, lambda_ = sp.symbols('epsilon lambda', real=True, nonnegative=True)\n",
    "\n",
    "# Define parameters\n",
    "eps_min, eps_mid, eps_rad = sp.symbols('eps_min eps_mid eps_rad', real=True)\n",
    "\n",
    "# Define the objective function f(epsilon)\n",
    "f = 0.5 * (epsilon - eps_min)**2\n",
    "\n",
    "# Define the inequality constraint g(epsilon) <= 0\n",
    "g = (epsilon - eps_mid)**2 - eps_rad**2  # Should be ‚â§ 0\n",
    "\n",
    "# Define the Fischer-Burmeister function\n",
    "def phi_FB(a, b):\n",
    "    return sp.sqrt(a**2 + b**2) - (a + b)\n",
    "\n",
    "# Compute derivatives\n",
    "f_eps = sp.diff(f, epsilon)\n",
    "g_eps = sp.diff(g, epsilon)\n",
    "\n",
    "A = sp.Matrix([epsilon, lambda_])\n",
    "\n",
    "# # Define residuals\n",
    "# R1 = f_eps + lambda_ * g_eps                # Stationarity condition\n",
    "# R2 = phi_FB(lambda_, -g)                    # Complementarity condition\n",
    "\n",
    "# R = sp.Matrix([R1, R2])                     # Residual vector\n",
    "\n",
    "# # Variables vector for Jacobian computation\n",
    "# R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = f + lambda_ * g\n",
    "R_ = L.diff(A)\n",
    "R_FB = sp.Matrix.vstack(R_[:-1, :], sp.Matrix([phi_FB(lambda_, -R_[-1, 0])]))\n",
    "R_FB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Jacobian matrix\n",
    "J = R_FB.jacobian(A)\n",
    "\n",
    "# Newton-Raphson solver function\n",
    "def newton_raphson(R_func, J_func, epsilon0, lambda0, tol=1e-8, max_iter=100):\n",
    "    x = np.array([epsilon0, lambda0], dtype=float)\n",
    "    for i in range(max_iter):\n",
    "        R_val = np.array(R_func(*x), dtype=float).flatten()\n",
    "        J_val = np.array(J_func(*x), dtype=float)\n",
    "        try:\n",
    "            delta = -np.linalg.solve(J_val, R_val)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print('Singular Jacobian matrix encountered in iteration', i+1)\n",
    "            break\n",
    "        x_new = x + delta\n",
    "        # Enforce lambda >= 0\n",
    "        print(f'Trial {i+1}: epsilon = {x_new[0]}, lambda = {x_new[1]}')\n",
    "        x_new[1] = max(0, x_new[1])\n",
    "        print(f'Correction {i+1}: epsilon = {x_new[0]}, lambda = {x_new[1]}')\n",
    "        # Check convergence\n",
    "        if np.linalg.norm(delta) < tol:\n",
    "            print(f'Converged in {i+1} iterations.')\n",
    "            return x_new\n",
    "        x = x_new\n",
    "    print('Did not converge.')\n",
    "    return x\n",
    "\n",
    "# ============================\n",
    "# Case 1: Minimum within range\n",
    "# ============================\n",
    "\n",
    "# Parameters for Case 1\n",
    "params_case1 = {eps_min: 0.0, eps_mid: 0.0, eps_rad: 1.0}\n",
    "\n",
    "# Substitute parameters into symbolic expressions\n",
    "R_subs_case1 = R.subs(params_case1)\n",
    "J_subs_case1 = J.subs(params_case1)\n",
    "\n",
    "# Lambdify the residual and Jacobian functions\n",
    "R_func_case1 = sp.lambdify((epsilon, lambda_), R_subs_case1, modules='numpy')\n",
    "J_func_case1 = sp.lambdify((epsilon, lambda_), J_subs_case1, modules='numpy')\n",
    "\n",
    "# Initial guesses for epsilon and lambda\n",
    "epsilon0_case1 = 0.0\n",
    "lambda0_case1 = 0.0\n",
    "\n",
    "# Solve using Newton-Raphson method\n",
    "print('Solving Case 1...')\n",
    "result_case1 = newton_raphson(R_func_case1, J_func_case1, epsilon0_case1, lambda0_case1)\n",
    "\n",
    "# Output results for Case 1\n",
    "print('\\nCase 1 Result:')\n",
    "print(f'epsilon = {result_case1[0]}')\n",
    "print(f'lambda = {result_case1[1]}')\n",
    "\n",
    "# =============================\n",
    "# Case 2: Minimum outside range\n",
    "# =============================\n",
    "\n",
    "# Parameters for Case 2\n",
    "params_case2 = {eps_min: 2.0, eps_mid: 0.0, eps_rad: 1.0}\n",
    "\n",
    "# Substitute parameters into symbolic expressions\n",
    "R_subs_case2 = R.subs(params_case2)\n",
    "J_subs_case2 = J.subs(params_case2)\n",
    "\n",
    "# Lambdify the residual and Jacobian functions\n",
    "R_func_case2 = sp.lambdify((epsilon, lambda_), R_subs_case2, modules='numpy')\n",
    "J_func_case2 = sp.lambdify((epsilon, lambda_), J_subs_case2, modules='numpy')\n",
    "\n",
    "# Initial guesses for epsilon and lambda\n",
    "epsilon0_case2 = 1.0  # Start at the boundary\n",
    "lambda0_case2 = 1.0   # Positive initial lambda\n",
    "\n",
    "# Solve using Newton-Raphson method\n",
    "print('\\nSolving Case 2...')\n",
    "result_case2 = newton_raphson(R_func_case2, J_func_case2, epsilon0_case2, lambda0_case2)\n",
    "\n",
    "# Output results for Case 2\n",
    "print('\\nCase 2 Result:')\n",
    "print(f'epsilon = {result_case2[0]}')\n",
    "print(f'lambda = {result_case2[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare the epsilon range for plotting\n",
    "eps = np.linspace(-2, 2, 200)\n",
    "\n",
    "# Case 1 parameters\n",
    "eps_min_c1 = 0.0\n",
    "eps_rad_c1 = 1.0\n",
    "# Case 1 solution\n",
    "eps_sol1 = result_case1[0]\n",
    "f_sol1 = 0.5*(eps_sol1 - eps_min_c1)**2\n",
    "\n",
    "# Compute f for Case 1\n",
    "f_case1 = 0.5*(eps - eps_min_c1)**2\n",
    "\n",
    "# Case 2 parameters\n",
    "eps_min_c2 = 2.0\n",
    "eps_rad_c2 = 1.0\n",
    "# Case 2 solution\n",
    "eps_sol2 = result_case2[0]\n",
    "f_sol2 = 0.5*(eps_sol2 - eps_min_c2)**2\n",
    "\n",
    "# Compute f for Case 2\n",
    "f_case2 = 0.5*(eps - eps_min_c2)**2\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Case 1 plot\n",
    "ax1.plot(eps, f_case1, label='f(epsilon)')\n",
    "ax1.axvspan(-eps_rad_c1, eps_rad_c1, color='green', alpha=0.2, label='Admissible range')\n",
    "ax1.scatter(eps_sol1, f_sol1, color='red', zorder=3, label='Solution')\n",
    "ax1.set_title('Case 1')\n",
    "ax1.set_xlabel('epsilon')\n",
    "ax1.set_ylabel('f(epsilon)')\n",
    "ax1.legend()\n",
    "\n",
    "# Case 2 plot\n",
    "ax2.plot(eps, f_case2, label='f(epsilon)')\n",
    "ax2.axvspan(-eps_rad_c2, eps_rad_c2, color='green', alpha=0.2, label='Admissible range')\n",
    "ax2.scatter(eps_sol2, f_sol2, color='red', zorder=3, label='Solution')\n",
    "ax2.set_title('Case 2')\n",
    "ax2.set_xlabel('epsilon')\n",
    "ax2.set_ylabel('f(epsilon)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmcs_matmod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
